{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "from copy import copy\n",
    "import json\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_l2_distances(pt, points):\n",
    "    return ((points - pt) ** 2).sum(axis=1)\n",
    "\n",
    "def calc_l1_distances(pt, points):\n",
    "    return (points - pt).abs().sum(axis=1)\n",
    "\n",
    "def get_sum_ord_calcer(sum_ord):\n",
    "    def calc_sum_ord_distances(pt, points):\n",
    "        return np.partition(points + pt, sum_ord)[:,sum_ord]\n",
    "    return calc_sum_ord_distances\n",
    "\n",
    "pt = np.array([1, 2, 3])\n",
    "pts = np.array([\n",
    "    [4, 0, 1],\n",
    "    [7, 6, 5],\n",
    "    [5, 5, 0]\n",
    "])\n",
    "assert np.all(get_sum_ord_calcer(1)(pt, pts) == np.array([4, 8, 6]))\n",
    "assert np.all(get_sum_ord_calcer(0)(pt, pts) == np.array([2, 8, 3]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_disorder_curve(item_features, item_ranks, metric_calcer,\n",
    "                            item_item_rank_lim=None, base_item_cout=1000):\n",
    "    item_count, query_count = item_ranks.shape\n",
    "    sample_count = item_count\n",
    "    if item_item_rank_lim is None:\n",
    "        item_item_rank_lim = item_count - 1\n",
    "    base_items = np.random.choice(item_count, base_item_cout)\n",
    "    disorder_multipliers = []\n",
    "\n",
    "    for base_item in base_items:\n",
    "        distances = metric_calcer(item_features[base_item], item_features)\n",
    "        item_order = np.argsort(distances)\n",
    "#         assert item_order[0] == base_item # fails if duplicates, fails for sum ord distance\n",
    "        item_item_ranks = np.argsort(item_order)\n",
    "        close_items = item_order[1: 1 + item_item_rank_lim]\n",
    "        \n",
    "        second_items = np.random.choice(close_items, sample_count)\n",
    "        qweries = np.random.choice(query_count, sample_count)\n",
    "        base_item_ranks = item_ranks[base_item, qweries]\n",
    "        second_item_ranks = item_ranks[second_items, qweries]\n",
    "        disorder_multipliers.append(\n",
    "            item_item_ranks[second_items] / (base_item_ranks + second_item_ranks)\n",
    "        )\n",
    "\n",
    "    disorder_multipliers = np.array(disorder_multipliers).flatten()\n",
    "    return np.quantile(disorder_multipliers, np.linspace(0, 1, 1001))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = \"collections\"\n",
    "item_count = 10 ** 6\n",
    "query_count = 1000\n",
    "\n",
    "ifeats = np.fromfile(\n",
    "    \"{}/data/model_scores/scores_train.bin\".format(dataset),\n",
    "    dtype=\"float32\"\n",
    ").reshape(item_count, query_count)\n",
    "train_ranks = np.fromfile(\n",
    "    \"{}/data/item_train_ranks.bin\".format(dataset),\n",
    "    dtype=\"float32\"\n",
    ").reshape(item_count, query_count)\n",
    "train_log_ranks = np.fromfile(\n",
    "    \"{}/data/item_train_log_ranks.bin\".format(dataset),\n",
    "    dtype=\"float32\"\n",
    ").reshape(item_count, query_count)\n",
    "test_ranks = np.fromfile(\n",
    "    \"{}/data/item_test_ranks.bin\".format(dataset),\n",
    "    dtype=\"float32\"\n",
    ").reshape(item_count, query_count)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "CALC_LIST = [\n",
    "    (\"l2_score\", ifeats, calc_l2_distances),\n",
    "    (\"l2_rank\", train_ranks, calc_l2_distances),\n",
    "    (\"l2_log_rank\", train_log_ranks, calc_l2_distances),\n",
    "    (\"l1_score\", ifeats, calc_l1_distances),\n",
    "    (\"l1_rank\", train_ranks, calc_l1_distances),\n",
    "    (\"l1_log_rank\", train_log_ranks, calc_l1_distances),\n",
    "    (\"ord_0\", train_ranks, get_sum_ord_calcer(0)),\n",
    "    (\"ord_1\", train_ranks, get_sum_ord_calcer(1)),\n",
    "    (\"ord_2\", train_ranks, get_sum_ord_calcer(2)),\n",
    "    (\"ord_5\", train_ranks, get_sum_ord_calcer(5)),\n",
    "    (\"ord_10\", train_ranks, get_sum_ord_calcer(10))\n",
    "]\n",
    "\n",
    "# CALC_LIST = [\n",
    "#     (\"l2_score\", ifeats, calc_l2_distances),\n",
    "#     (\"l2_log_rank\", train_log_ranks, calc_l2_distances),\n",
    "# ]\n",
    "base_item_cout=1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "backup_file = \"{}/data/disorder_curves_{}_samples.json\".format(dataset, base_item_cout)\n",
    "if not os.path.isfile(backup_file):\n",
    "    results = OrderedDict()\n",
    "    for label, feats, dist_calcer in CALC_LIST:\n",
    "        for data_part, ranks in [(\"_train\", train_ranks), (\"_test\", test_ranks)]:\n",
    "            curve = estimate_disorder_curve(\n",
    "                feats, ranks, dist_calcer, base_item_cout=base_item_cout)\n",
    "            results[label + data_part] = list(curve)\n",
    "    with open(backup_file, \"w\") as fout:\n",
    "        json.dump(results, fout, indent=4, sort_keys=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'results' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-100f62972f2f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'results' is not defined"
     ]
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(backup_file) as fin:\n",
    "    results = json.load(fin)\n",
    "    keys = sorted(results.keys())\n",
    "    results = OrderedDict((key, np.array(results[key])) for key in keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_range = np.arange(900, 1001)\n",
    "\n",
    "plt.yscale(\"log\")\n",
    "for label, curve in results.items():\n",
    "    plt.plot(plot_range, curve[plot_range], label=label)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "percentiles = np.array([900, 950, 980, 990, 995, 999, 1000])\n",
    "\n",
    "result_table = []\n",
    "columns = [\"metric\"] + [\"{:.3}\".format(q) for q in percentiles * 0.001]\n",
    "for label, curve in results.items():\n",
    "    result_table.append([label] + list(curve[percentiles]))\n",
    "pd.DataFrame(result_table, columns=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raise StopIteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test data\n",
    "\n",
    "iranks = np.array([\n",
    "    [1],\n",
    "    [2],\n",
    "    [3]\n",
    "])\n",
    "ifeats = np.array([\n",
    "    [1],\n",
    "    [2],\n",
    "    [3]\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "curve = estimate_disorder_curve(ifeats, iranks, calc_l2_distances, base_item_cout=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2.68003109e-05, 2.74422998e-02, 5.56524824e-02, ...,\n",
       "       9.16645442e+00, 1.16852408e+01, 9.40127289e+01])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "curve"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
